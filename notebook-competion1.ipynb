{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Cette page doit être lancée sur Kaggle, depuis la compétition pour avoir accès aux données. Sinon vous devez récupérer les données séparément.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom IPython.display import FileLink\nSEED = 25\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\nOUTPUT_DIR = '/kaggle/working/outputs'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-12T16:50:23.120534Z","iopub.execute_input":"2023-05-12T16:50:23.122299Z","iopub.status.idle":"2023-05-12T16:50:34.633309Z","shell.execute_reply.started":"2023-05-12T16:50:23.122243Z","shell.execute_reply":"2023-05-12T16:50:34.631952Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/outputs","metadata":{"execution":{"iopub.status.busy":"2023-05-12T16:50:45.050104Z","iopub.execute_input":"2023-05-12T16:50:45.051025Z","iopub.status.idle":"2023-05-12T16:50:46.148551Z","shell.execute_reply.started":"2023-05-12T16:50:45.050971Z","shell.execute_reply":"2023-05-12T16:50:46.146698Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Lire les images\n\ncf https://keras.io/api/data_loading/image/ et \nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory","metadata":{}},{"cell_type":"code","source":"directory_path = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data\"\nds_train, ds_val = tf.keras.utils.image_dataset_from_directory(directory_path, labels='inferred',subset='both',shuffle=True,validation_split=0.2,seed=SEED,image_size=(16,24))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T16:50:50.049869Z","iopub.execute_input":"2023-05-12T16:50:50.050478Z","iopub.status.idle":"2023-05-12T16:51:00.101979Z","shell.execute_reply.started":"2023-05-12T16:50:50.050426Z","shell.execute_reply":"2023-05-12T16:51:00.100611Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 35515 files belonging to 10 classes.\nUsing 28412 files for training.\nUsing 7103 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"ds_train","metadata":{"execution":{"iopub.status.busy":"2023-05-12T08:21:44.200721Z","iopub.execute_input":"2023-05-12T08:21:44.201149Z","iopub.status.idle":"2023-05-12T08:21:44.211514Z","shell.execute_reply.started":"2023-05-12T08:21:44.201106Z","shell.execute_reply":"2023-05-12T08:21:44.210085Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<BatchDataset element_spec=(TensorSpec(shape=(None, 16, 24, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Résultat à soumettre","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:53:05.081093Z","iopub.execute_input":"2022-05-02T16:53:05.081503Z","iopub.status.idle":"2022-05-02T16:53:05.087029Z","shell.execute_reply.started":"2022-05-02T16:53:05.081444Z","shell.execute_reply":"2022-05-02T16:53:05.085976Z"}}},{"cell_type":"code","source":"from tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, MaxPooling2D, Dropout,Flatten, Dense, BatchNormalization\n\ndef build_model() -> Model:\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Rescaling(1./255, input_shape=(16, 24, 3)),\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPooling2D((2, 2)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(10,activation='softmax')\n    ])\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                metrics=['accuracy'])\n    \n    return model\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:01:52.602508Z","iopub.execute_input":"2023-05-12T17:01:52.602986Z","iopub.status.idle":"2023-05-12T17:01:52.955496Z","shell.execute_reply.started":"2023-05-12T17:01:52.602941Z","shell.execute_reply":"2023-05-12T17:01:52.954025Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling (Rescaling)       (None, 16, 24, 3)         0         \n                                                                 \n conv2d (Conv2D)             (None, 14, 22, 32)        896       \n                                                                 \n batch_normalization (BatchN  (None, 14, 22, 32)       128       \n ormalization)                                                   \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 7, 11, 32)        0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 7, 11, 32)         0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 7, 11, 64)         18496     \n                                                                 \n batch_normalization_1 (Batc  (None, 7, 11, 64)        256       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 3, 5, 64)         0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 3, 5, 64)          0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 3, 5, 128)         73856     \n                                                                 \n batch_normalization_2 (Batc  (None, 3, 5, 128)        512       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 1, 2, 128)        0         \n 2D)                                                             \n                                                                 \n dropout_2 (Dropout)         (None, 1, 2, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 256)               0         \n                                                                 \n dense (Dense)               (None, 128)               32896     \n                                                                 \n dropout_3 (Dropout)         (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 128,330\nTrainable params: 127,882\nNon-trainable params: 448\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_phase(model):\n    file_name = f'reco_nav_{model.name}.csv'\n    X_test = np.load('/kaggle/input/navires-2023-la-mano/test.npy', allow_pickle=True)\n    X_test = X_test.astype('float32')\n    res = model.predict(X_test).argmax(axis=1)\n    df = pd.DataFrame({\"Category\":res})\n    df.to_csv(os.path.join(OUTPUT_DIR,file_name), index_label=\"Id\")\n\ndef save_history(model,history):\n    history_df = pd.DataFrame(history.history)\n    hist_file_name = f\"history_{model.name}.csv\"\n    history_df.to_csv(os.path.join(OUTPUT_DIR,hist_file_name))\n\ndef save_model(model):\n    model_file_name = f\"{model.name}.h5\"\n    model.save(os.path.join(OUTPUT_DIR,model_file_name))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:01:55.468813Z","iopub.execute_input":"2023-05-12T17:01:55.469363Z","iopub.status.idle":"2023-05-12T17:01:55.484223Z","shell.execute_reply.started":"2023-05-12T17:01:55.469315Z","shell.execute_reply":"2023-05-12T17:01:55.482093Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CheckValidationLossCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, patience=0):\n        self.patience = patience\n        self.counter = 0\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_loss = logs.get('val_loss')\n        train_loss = logs.get('loss')\n        if val_loss < train_loss:\n            self.counter = 0\n            print(f\"\\nValidation loss ({val_loss:.4f}) is less than training loss ({train_loss:.4f})\")\n        else:\n            self.counter +=1\n            \n        if(self.counter == self.patience):\n            self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:04:58.107524Z","iopub.execute_input":"2023-05-12T17:04:58.108031Z","iopub.status.idle":"2023-05-12T17:04:58.118228Z","shell.execute_reply.started":"2023-05-12T17:04:58.107986Z","shell.execute_reply":"2023-05-12T17:04:58.116838Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train_and_test(epochs=50,model=None):\n    callback = CheckValidationLossCallback(patience=3)#tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n    if model is None:\n        model = build_model() \n    history = model.fit(ds_train,epochs=epochs,validation_data=ds_val,callbacks=[callback])\n    test_phase(model)\n    save_model(model)\n\n\ntrain_and_test(epochs=75,model=model)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:04:58.777064Z","iopub.execute_input":"2023-05-12T17:04:58.778328Z","iopub.status.idle":"2023-05-12T17:39:48.717448Z","shell.execute_reply.started":"2023-05-12T17:04:58.778275Z","shell.execute_reply":"2023-05-12T17:39:48.716069Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/75\n887/888 [============================>.] - ETA: 0s - loss: 1.7870 - accuracy: 0.3779\nValidation loss (1.6029) is less than training loss (1.7868)\n888/888 [==============================] - 27s 31ms/step - loss: 1.7868 - accuracy: 0.3780 - val_loss: 1.6029 - val_accuracy: 0.4440\nEpoch 2/75\n887/888 [============================>.] - ETA: 0s - loss: 1.7038 - accuracy: 0.4064\nValidation loss (1.4804) is less than training loss (1.7036)\n888/888 [==============================] - 27s 30ms/step - loss: 1.7036 - accuracy: 0.4065 - val_loss: 1.4804 - val_accuracy: 0.4888\nEpoch 3/75\n886/888 [============================>.] - ETA: 0s - loss: 1.6416 - accuracy: 0.4320\nValidation loss (1.4279) is less than training loss (1.6418)\n888/888 [==============================] - 27s 31ms/step - loss: 1.6418 - accuracy: 0.4319 - val_loss: 1.4279 - val_accuracy: 0.4998\nEpoch 4/75\n887/888 [============================>.] - ETA: 0s - loss: 1.5921 - accuracy: 0.4481\nValidation loss (1.3941) is less than training loss (1.5921)\n888/888 [==============================] - 27s 30ms/step - loss: 1.5921 - accuracy: 0.4481 - val_loss: 1.3941 - val_accuracy: 0.5175\nEpoch 5/75\n888/888 [==============================] - ETA: 0s - loss: 1.5388 - accuracy: 0.4668\nValidation loss (1.3474) is less than training loss (1.5388)\n888/888 [==============================] - 27s 31ms/step - loss: 1.5388 - accuracy: 0.4668 - val_loss: 1.3474 - val_accuracy: 0.5310\nEpoch 6/75\n888/888 [==============================] - ETA: 0s - loss: 1.5057 - accuracy: 0.4796\nValidation loss (1.3506) is less than training loss (1.5057)\n888/888 [==============================] - 27s 31ms/step - loss: 1.5057 - accuracy: 0.4796 - val_loss: 1.3506 - val_accuracy: 0.5351\nEpoch 7/75\n887/888 [============================>.] - ETA: 0s - loss: 1.4695 - accuracy: 0.4904\nValidation loss (1.2907) is less than training loss (1.4695)\n888/888 [==============================] - 28s 31ms/step - loss: 1.4695 - accuracy: 0.4903 - val_loss: 1.2907 - val_accuracy: 0.5526\nEpoch 8/75\n887/888 [============================>.] - ETA: 0s - loss: 1.4450 - accuracy: 0.4996\nValidation loss (1.2909) is less than training loss (1.4450)\n888/888 [==============================] - 28s 32ms/step - loss: 1.4450 - accuracy: 0.4995 - val_loss: 1.2909 - val_accuracy: 0.5526\nEpoch 9/75\n887/888 [============================>.] - ETA: 0s - loss: 1.4218 - accuracy: 0.5097\nValidation loss (1.2433) is less than training loss (1.4218)\n888/888 [==============================] - 27s 30ms/step - loss: 1.4218 - accuracy: 0.5096 - val_loss: 1.2433 - val_accuracy: 0.5720\nEpoch 10/75\n887/888 [============================>.] - ETA: 0s - loss: 1.3938 - accuracy: 0.5196\nValidation loss (1.2232) is less than training loss (1.3938)\n888/888 [==============================] - 28s 31ms/step - loss: 1.3938 - accuracy: 0.5195 - val_loss: 1.2232 - val_accuracy: 0.5791\nEpoch 11/75\n886/888 [============================>.] - ETA: 0s - loss: 1.3725 - accuracy: 0.5221\nValidation loss (1.2109) is less than training loss (1.3721)\n888/888 [==============================] - 27s 30ms/step - loss: 1.3721 - accuracy: 0.5223 - val_loss: 1.2109 - val_accuracy: 0.5795\nEpoch 12/75\n886/888 [============================>.] - ETA: 0s - loss: 1.3484 - accuracy: 0.5328\nValidation loss (1.1966) is less than training loss (1.3485)\n888/888 [==============================] - 27s 31ms/step - loss: 1.3485 - accuracy: 0.5327 - val_loss: 1.1966 - val_accuracy: 0.5845\nEpoch 13/75\n887/888 [============================>.] - ETA: 0s - loss: 1.3305 - accuracy: 0.5416\nValidation loss (1.1719) is less than training loss (1.3306)\n888/888 [==============================] - 27s 30ms/step - loss: 1.3306 - accuracy: 0.5417 - val_loss: 1.1719 - val_accuracy: 0.5937\nEpoch 14/75\n887/888 [============================>.] - ETA: 0s - loss: 1.3152 - accuracy: 0.5438\nValidation loss (1.1575) is less than training loss (1.3153)\n888/888 [==============================] - 28s 32ms/step - loss: 1.3153 - accuracy: 0.5437 - val_loss: 1.1575 - val_accuracy: 0.6016\nEpoch 15/75\n887/888 [============================>.] - ETA: 0s - loss: 1.2958 - accuracy: 0.5515\nValidation loss (1.1579) is less than training loss (1.2958)\n888/888 [==============================] - 27s 31ms/step - loss: 1.2958 - accuracy: 0.5514 - val_loss: 1.1579 - val_accuracy: 0.6003\nEpoch 16/75\n886/888 [============================>.] - ETA: 0s - loss: 1.2861 - accuracy: 0.5516\nValidation loss (1.1449) is less than training loss (1.2862)\n888/888 [==============================] - 27s 30ms/step - loss: 1.2862 - accuracy: 0.5515 - val_loss: 1.1449 - val_accuracy: 0.6055\nEpoch 17/75\n888/888 [==============================] - ETA: 0s - loss: 1.2661 - accuracy: 0.5610\nValidation loss (1.1373) is less than training loss (1.2661)\n888/888 [==============================] - 28s 32ms/step - loss: 1.2661 - accuracy: 0.5610 - val_loss: 1.1373 - val_accuracy: 0.6095\nEpoch 18/75\n886/888 [============================>.] - ETA: 0s - loss: 1.2540 - accuracy: 0.5609\nValidation loss (1.1337) is less than training loss (1.2543)\n888/888 [==============================] - 29s 32ms/step - loss: 1.2543 - accuracy: 0.5607 - val_loss: 1.1337 - val_accuracy: 0.6055\nEpoch 19/75\n887/888 [============================>.] - ETA: 0s - loss: 1.2453 - accuracy: 0.5656\nValidation loss (1.1111) is less than training loss (1.2451)\n888/888 [==============================] - 30s 33ms/step - loss: 1.2451 - accuracy: 0.5657 - val_loss: 1.1111 - val_accuracy: 0.6186\nEpoch 20/75\n888/888 [==============================] - ETA: 0s - loss: 1.2283 - accuracy: 0.5731\nValidation loss (1.1087) is less than training loss (1.2283)\n888/888 [==============================] - 29s 32ms/step - loss: 1.2283 - accuracy: 0.5731 - val_loss: 1.1087 - val_accuracy: 0.6204\nEpoch 21/75\n887/888 [============================>.] - ETA: 0s - loss: 1.2172 - accuracy: 0.5757\nValidation loss (1.1109) is less than training loss (1.2174)\n888/888 [==============================] - 28s 31ms/step - loss: 1.2174 - accuracy: 0.5756 - val_loss: 1.1109 - val_accuracy: 0.6206\nEpoch 22/75\n888/888 [==============================] - ETA: 0s - loss: 1.2113 - accuracy: 0.5766\nValidation loss (1.0909) is less than training loss (1.2113)\n888/888 [==============================] - 27s 31ms/step - loss: 1.2113 - accuracy: 0.5766 - val_loss: 1.0909 - val_accuracy: 0.6254\nEpoch 23/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1935 - accuracy: 0.5827\nValidation loss (1.0929) is less than training loss (1.1940)\n888/888 [==============================] - 27s 31ms/step - loss: 1.1940 - accuracy: 0.5824 - val_loss: 1.0929 - val_accuracy: 0.6251\nEpoch 24/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1881 - accuracy: 0.5860\nValidation loss (1.0869) is less than training loss (1.1881)\n888/888 [==============================] - 28s 32ms/step - loss: 1.1881 - accuracy: 0.5859 - val_loss: 1.0869 - val_accuracy: 0.6259\nEpoch 25/75\n888/888 [==============================] - ETA: 0s - loss: 1.1766 - accuracy: 0.5871\nValidation loss (1.0938) is less than training loss (1.1766)\n888/888 [==============================] - 27s 30ms/step - loss: 1.1766 - accuracy: 0.5871 - val_loss: 1.0938 - val_accuracy: 0.6227\nEpoch 26/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1762 - accuracy: 0.5916\nValidation loss (1.0754) is less than training loss (1.1763)\n888/888 [==============================] - 27s 30ms/step - loss: 1.1763 - accuracy: 0.5915 - val_loss: 1.0754 - val_accuracy: 0.6313\nEpoch 27/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1541 - accuracy: 0.5977\nValidation loss (1.0729) is less than training loss (1.1541)\n888/888 [==============================] - 28s 31ms/step - loss: 1.1541 - accuracy: 0.5977 - val_loss: 1.0729 - val_accuracy: 0.6371\nEpoch 28/75\n888/888 [==============================] - ETA: 0s - loss: 1.1446 - accuracy: 0.5983\nValidation loss (1.0529) is less than training loss (1.1446)\n888/888 [==============================] - 28s 32ms/step - loss: 1.1446 - accuracy: 0.5983 - val_loss: 1.0529 - val_accuracy: 0.6427\nEpoch 29/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1358 - accuracy: 0.6027\nValidation loss (1.0876) is less than training loss (1.1359)\n888/888 [==============================] - 28s 32ms/step - loss: 1.1359 - accuracy: 0.6027 - val_loss: 1.0876 - val_accuracy: 0.6276\nEpoch 30/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1350 - accuracy: 0.6032\nValidation loss (1.0621) is less than training loss (1.1348)\n888/888 [==============================] - 28s 32ms/step - loss: 1.1348 - accuracy: 0.6032 - val_loss: 1.0621 - val_accuracy: 0.6379\nEpoch 31/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1326 - accuracy: 0.6009\nValidation loss (1.0462) is less than training loss (1.1324)\n888/888 [==============================] - 29s 32ms/step - loss: 1.1324 - accuracy: 0.6010 - val_loss: 1.0462 - val_accuracy: 0.6424\nEpoch 32/75\n887/888 [============================>.] - ETA: 0s - loss: 1.1109 - accuracy: 0.6067\nValidation loss (1.0580) is less than training loss (1.1110)\n888/888 [==============================] - 27s 31ms/step - loss: 1.1110 - accuracy: 0.6066 - val_loss: 1.0580 - val_accuracy: 0.6333\nEpoch 33/75\n886/888 [============================>.] - ETA: 0s - loss: 1.1103 - accuracy: 0.6105\nValidation loss (1.0388) is less than training loss (1.1103)\n888/888 [==============================] - 27s 31ms/step - loss: 1.1103 - accuracy: 0.6106 - val_loss: 1.0388 - val_accuracy: 0.6449\nEpoch 34/75\n886/888 [============================>.] - ETA: 0s - loss: 1.1014 - accuracy: 0.6157\nValidation loss (1.0644) is less than training loss (1.1012)\n888/888 [==============================] - 28s 31ms/step - loss: 1.1012 - accuracy: 0.6158 - val_loss: 1.0644 - val_accuracy: 0.6327\nEpoch 35/75\n888/888 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.6152\nValidation loss (1.0267) is less than training loss (1.0986)\n888/888 [==============================] - 27s 31ms/step - loss: 1.0986 - accuracy: 0.6152 - val_loss: 1.0267 - val_accuracy: 0.6501\nEpoch 36/75\n888/888 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.6193\nValidation loss (1.0725) is less than training loss (1.0881)\n888/888 [==============================] - 27s 31ms/step - loss: 1.0881 - accuracy: 0.6193 - val_loss: 1.0725 - val_accuracy: 0.6314\nEpoch 37/75\n887/888 [============================>.] - ETA: 0s - loss: 1.0832 - accuracy: 0.6196\nValidation loss (1.0149) is less than training loss (1.0833)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0833 - accuracy: 0.6195 - val_loss: 1.0149 - val_accuracy: 0.6518\nEpoch 38/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0787 - accuracy: 0.6203\nValidation loss (1.0297) is less than training loss (1.0784)\n888/888 [==============================] - 27s 31ms/step - loss: 1.0784 - accuracy: 0.6205 - val_loss: 1.0297 - val_accuracy: 0.6454\nEpoch 39/75\n887/888 [============================>.] - ETA: 0s - loss: 1.0697 - accuracy: 0.6251\nValidation loss (1.0135) is less than training loss (1.0699)\n888/888 [==============================] - 28s 31ms/step - loss: 1.0699 - accuracy: 0.6251 - val_loss: 1.0135 - val_accuracy: 0.6559\nEpoch 40/75\n888/888 [==============================] - ETA: 0s - loss: 1.0695 - accuracy: 0.6261\nValidation loss (1.0120) is less than training loss (1.0695)\n888/888 [==============================] - 29s 32ms/step - loss: 1.0695 - accuracy: 0.6261 - val_loss: 1.0120 - val_accuracy: 0.6544\nEpoch 41/75\n888/888 [==============================] - ETA: 0s - loss: 1.0623 - accuracy: 0.6266\nValidation loss (1.0248) is less than training loss (1.0623)\n888/888 [==============================] - 29s 33ms/step - loss: 1.0623 - accuracy: 0.6266 - val_loss: 1.0248 - val_accuracy: 0.6517\nEpoch 42/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0499 - accuracy: 0.6304\nValidation loss (1.0277) is less than training loss (1.0500)\n888/888 [==============================] - 29s 32ms/step - loss: 1.0500 - accuracy: 0.6302 - val_loss: 1.0277 - val_accuracy: 0.6469\nEpoch 43/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0518 - accuracy: 0.6307\nValidation loss (1.0214) is less than training loss (1.0515)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0515 - accuracy: 0.6308 - val_loss: 1.0214 - val_accuracy: 0.6486\nEpoch 44/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0411 - accuracy: 0.6352\nValidation loss (0.9974) is less than training loss (1.0415)\n888/888 [==============================] - 26s 30ms/step - loss: 1.0415 - accuracy: 0.6351 - val_loss: 0.9974 - val_accuracy: 0.6592\nEpoch 45/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.6350\nValidation loss (1.0018) is less than training loss (1.0356)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0356 - accuracy: 0.6349 - val_loss: 1.0018 - val_accuracy: 0.6554\nEpoch 46/75\n888/888 [==============================] - 26s 29ms/step - loss: 1.0301 - accuracy: 0.6376 - val_loss: 1.0402 - val_accuracy: 0.6440\nEpoch 47/75\n886/888 [============================>.] - ETA: 0s - loss: 1.0289 - accuracy: 0.6381\nValidation loss (1.0096) is less than training loss (1.0294)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0294 - accuracy: 0.6379 - val_loss: 1.0096 - val_accuracy: 0.6531\nEpoch 48/75\n887/888 [============================>.] - ETA: 0s - loss: 1.0243 - accuracy: 0.6397\nValidation loss (1.0100) is less than training loss (1.0242)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0242 - accuracy: 0.6397 - val_loss: 1.0100 - val_accuracy: 0.6555\nEpoch 49/75\n887/888 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.6416\nValidation loss (1.0105) is less than training loss (1.0212)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0212 - accuracy: 0.6415 - val_loss: 1.0105 - val_accuracy: 0.6528\nEpoch 50/75\n888/888 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.6471\nValidation loss (0.9944) is less than training loss (1.0073)\n888/888 [==============================] - 27s 31ms/step - loss: 1.0073 - accuracy: 0.6471 - val_loss: 0.9944 - val_accuracy: 0.6590\nEpoch 51/75\n888/888 [==============================] - 27s 31ms/step - loss: 0.9997 - accuracy: 0.6492 - val_loss: 1.0048 - val_accuracy: 0.6566\nEpoch 52/75\n887/888 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6483\nValidation loss (0.9810) is less than training loss (1.0083)\n888/888 [==============================] - 27s 30ms/step - loss: 1.0083 - accuracy: 0.6482 - val_loss: 0.9810 - val_accuracy: 0.6630\nEpoch 53/75\n888/888 [==============================] - 27s 30ms/step - loss: 1.0012 - accuracy: 0.6481 - val_loss: 1.0374 - val_accuracy: 0.6424\nEpoch 54/75\n887/888 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.6486\nValidation loss (0.9871) is less than training loss (0.9967)\n888/888 [==============================] - 26s 30ms/step - loss: 0.9967 - accuracy: 0.6486 - val_loss: 0.9871 - val_accuracy: 0.6558\nEpoch 55/75\n888/888 [==============================] - 27s 30ms/step - loss: 0.9905 - accuracy: 0.6511 - val_loss: 0.9948 - val_accuracy: 0.6600\nEpoch 56/75\n888/888 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.6518\nValidation loss (0.9727) is less than training loss (0.9863)\n888/888 [==============================] - 27s 30ms/step - loss: 0.9863 - accuracy: 0.6518 - val_loss: 0.9727 - val_accuracy: 0.6690\nEpoch 57/75\n888/888 [==============================] - 27s 30ms/step - loss: 0.9824 - accuracy: 0.6550 - val_loss: 0.9985 - val_accuracy: 0.6582\nEpoch 58/75\n888/888 [==============================] - 27s 30ms/step - loss: 0.9805 - accuracy: 0.6519 - val_loss: 0.9827 - val_accuracy: 0.6592\nEpoch 59/75\n888/888 [==============================] - 27s 31ms/step - loss: 0.9687 - accuracy: 0.6601 - val_loss: 0.9942 - val_accuracy: 0.6625\n116/116 [==============================] - 1s 7ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"! zip -r  `date +%m%d%H%M`_result.zip outputs","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:40:14.645202Z","iopub.execute_input":"2023-05-12T17:40:14.645733Z","iopub.status.idle":"2023-05-12T17:40:15.888250Z","shell.execute_reply.started":"2023-05-12T17:40:14.645688Z","shell.execute_reply":"2023-05-12T17:40:15.886405Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"  adding: outputs/ (stored 0%)\n  adding: outputs/reco_nav_sequential.csv (deflated 61%)\n  adding: outputs/sequential.h5 (deflated 12%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf ships32/","metadata":{"execution":{"iopub.status.busy":"2023-05-12T09:05:12.808043Z","iopub.execute_input":"2023-05-12T09:05:12.808495Z","iopub.status.idle":"2023-05-12T09:05:13.926032Z","shell.execute_reply.started":"2023-05-12T09:05:12.808448Z","shell.execute_reply":"2023-05-12T09:05:13.923904Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(\"Nombre de couches : \", len(model.layers))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T09:05:13.931129Z","iopub.execute_input":"2023-05-12T09:05:13.931674Z","iopub.status.idle":"2023-05-12T09:05:13.939321Z","shell.execute_reply.started":"2023-05-12T09:05:13.931599Z","shell.execute_reply":"2023-05-12T09:05:13.937676Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Nombre de couches :  17\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}